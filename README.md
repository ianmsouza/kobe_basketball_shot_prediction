# Projeto Final - Engenharia de Machine Learning (25E1_3)

## üéØ Predi√ß√£o de Arremessos de Kobe Bryant com Machine Learning

Este projeto tem como objetivo desenvolver um modelo preditivo utilizando t√©cnicas de Machine Learning para prever o sucesso dos arremessos realizados pelo famoso jogador de basquete Kobe Bryant durante sua carreira na NBA. O projeto explora abordagens de regress√£o log√≠stica e classifica√ß√£o com √°rvore de decis√£o para prever acertos ou erros dos arremessos.

---

## üß± Estrutura do Projeto (TDSP)

```
infnet-25E1_3/
‚îú‚îÄ‚îÄ Code/
‚îÇ   ‚îú‚îÄ‚îÄ DataPrep/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_preparation.py
‚îÇ   ‚îú‚îÄ‚îÄ Model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
‚îÇ   ‚îî‚îÄ‚îÄ Operationalization/
‚îÇ       ‚îú‚îÄ‚îÄ mlruns/
‚îÇ       ‚îú‚îÄ‚îÄ logs.log
‚îÇ       ‚îú‚îÄ‚îÄ aplicacao.py
‚îÇ       ‚îú‚îÄ‚îÄ main_pipeline.py
‚îÇ       ‚îú‚îÄ‚îÄ streamlit_dashboard_mapa.py
‚îÇ       ‚îú‚îÄ‚îÄ streamlit_dashboard_simulacao.py
‚îÇ       ‚îî‚îÄ‚îÄ streamlit_dashboard.py
‚îú‚îÄ‚îÄ Data/
‚îÇ   ‚îú‚îÄ‚îÄ Logs/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ simulacoes.csv
‚îÇ   ‚îú‚îÄ‚îÄ Raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset_kobe_dev.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_kobe_prod.parquet
‚îÇ   ‚îú‚îÄ‚îÄ Processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_filtered.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_train.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_test.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predictions_prod.parquet
‚îÇ   ‚îú‚îÄ‚îÄ Modeling/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ modelo_final.pkl
‚îú‚îÄ‚îÄ Docs/
‚îÇ   ‚îú‚îÄ‚îÄ Imagens/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ charlotte_key_zone.jpeg
‚îÇ   ‚îú‚îÄ‚îÄ Diagramas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fluxograma_questao2.png
‚îÇ   ‚îú‚îÄ‚îÄ Project/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ execucao_pipeline.md
‚îú‚îÄ‚îÄ Notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ analisys_roc.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ criar_diagrama_questao_2.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ criar_estrutura_tdsp.ipynb
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ environment.yml
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Como Executar

### 1. Criar ambiente Conda e instalar depend√™ncias:
```bash
conda create -n infnet-25E1_3_v2 python=3.9.21
conda activate infnet-25E1_3_v2
pip install -r requirements.txt
```
ou YAML 
```bash
conda env create -f environment.yml
```

### 2. Rodar o pipeline completo:
```bash
# Executar todas as etapas em sequ√™ncia
python Code/Operationalization/main_pipeline.py
```

### 3. Rodar o dashboard:
```bash
# Dashboard anal√≠tico com m√©tricas e gr√°ficos
streamlit run Code/Operationalization/streamlit_dashboard.py

# Mapa interativo dos arremessos
streamlit run Code/Operationalization/streamlit_dashboard_mapa.py

# Simulador de jogadas
streamlit run Code/Operationalization/streamlit_dashboard_simulacao.py
```

### 4. Ver o MLflow (opcional):
```bash
mlflow ui
```
Acesse: [http://localhost:5000](http://localhost:5000)

---

## üõ†Ô∏è Tecnologias Utilizadas
- Python 3.9.21
- PyCaret 3.3.2
- Scikit-Learn 1.4.2
- MLflow 1.30.0
- Streamlit 1.43.2
- Pandas 1.5.3
- NumPy 1.26.4
- Matplotlib 3.7.5
- Seaborn 0.13.2

---

## üìà M√©tricas Finais (Produ√ß√£o)

| **M√©trica**           | **Valor**         |
|-----------------------|-------------------|
| Modelo Escolhido      | Regress√£o Log√≠stica |
| Log Loss (Produ√ß√£o)   | 0.6289            |
| F1-Score (Produ√ß√£o)   | 0.1645             |

> üîç O modelo de **Regress√£o Log√≠stica** foi selecionado para produ√ß√£o por apresentar **desempenho mais consistente e estabilidade no ambiente de produ√ß√£o**, mesmo com F1-Score modesto.
>
> üìâ A **√Årvore de Decis√£o** apresentou overfitting (F1-Score de 0.1072 em produ√ß√£o), enquanto a regress√£o log√≠stica manteve uma generaliza√ß√£o mais robusta.

---

## üìä Dataset
- [Kaggle - Kobe Bryant Shot Selection](https://www.kaggle.com/c/kobe-bryant-shot-selection/data)
- [Dados de desenvolvimento e produ√ß√£o](https://github.com/tciodaro/eng_ml/tree/main/data)

---

## üß† Projeto para a disciplina:
**Engenharia de Machine Learning (25E1_3)**  
**Instituto Infnet ‚Äì 2025**

---

## üìù Observa√ß√µes finais
- Todos os experimentos e m√©tricas s√£o registrados no MLflow
- O pipeline automatizado contempla 3 etapas: prepara√ß√£o ‚Üí treinamento ‚Üí aplica√ß√£o
- Cada etapa registra uma rodada espec√≠fica no MLflow:
  - `PreparacaoDados`
  - `Treinamento`
  - `PipelineAplicacao`

<br>

# **Respostas do projeto**

### **Quest√£o 1)**
#### A solu√ß√£o criada nesse projeto deve ser disponibilizada em reposit√≥rio git e disponibilizada em servidor de reposit√≥rios (Github (recomendado), Bitbucket ou Gitlab). O projeto deve obedecer o Framework TDSP da Microsoft (estrutura de arquivos, arquivo requirements.txt e arquivo README - com as respostas pedidas nesse projeto, al√©m de outras informa√ß√µes pertinentes). Todos os artefatos produzidos dever√£o conter informa√ß√µes referentes a esse projeto (n√£o ser√£o aceitos documentos vazios ou fora de contexto). Escreva o link para seu reposit√≥rio. 

>Resposta:
> <br>
> Link do GitHub: [https://github.com/ianmsouza/kobe_basketball_shot_prediction](https://github.com/ianmsouza/kobe_basketball_shot_prediction)

### **Quest√£o 2)**
#### Iremos desenvolver um preditor de arremessos usando duas abordagens (regress√£o e classifica√ß√£o) para prever se o "Black Mamba" (apelido de Kobe) acertou ou errou a cesta.<br><br>Baixe os dados de desenvolvimento e produ√ß√£o [aqui](https://github.com/tciodaro/eng_ml/tree/main/data) (datasets: dataset_kobe_dev.parquet e dataset_kobe_prod.parquet). Salve-os numa pasta /data/raw na raiz do seu reposit√≥rio.<br><br>Para come√ßar o desenvolvimento, desenhe um diagrama que demonstra todas as etapas necess√°rias para esse projeto, desde a aquisi√ß√£o de dados, passando pela cria√ß√£o dos modelos, indo at√© a opera√ß√£o do modelo.

> Resposta:
> <br><br>
> **1Ô∏è‚É£ Aquisi√ß√£o de Dados**
> - Coleta dos dados brutos fornecidos (`dataset_kobe_dev.parquet` e `dataset_kobe_prod.parquet`).
> - Armazenamento na pasta `/Data/Raw`.
>
> **2Ô∏è‚É£ Pr√©-processamento dos Dados**
> - Remo√ß√£o de valores ausentes.
> - **Aplica√ß√£o de clipping** em features para limitar outliers (ex: `shot_distance` entre 0 e 35 p√©s).
> - Sele√ß√£o das colunas relevantes: `lat`, `lon`, `minutes_remaining`, etc.
> - Salvamento dos dados tratados em `/Data/Processed`.
>
> ‚ÑπÔ∏è *Nota:* Os limites de clipping foram definidos com base na distribui√ß√£o hist√≥rica dos dados de treino e em conhecimento de dom√≠nio:
> 
> - `shot_distance` (0-35 p√©s): Arremessos al√©m de 35 p√©s s√£o raros na NBA e geralmente pouco precisos.
> - `lat` (33.2 - 34.1) e `lon` (-118.52 - -118.02): Coordenadas geogr√°ficas da quadra do Staples Center em Los Angeles, onde Kobe jogou a maior parte da carreira.
>
> **3Ô∏è‚É£ Separa√ß√£o em Treino/Teste**
> - Separa√ß√£o estratificada dos dados (80% treino, 20% teste).
> - Bases armazenadas em `/Data/Processed/base_train.parquet` e `base_test.parquet`.
>
> **4Ô∏è‚É£ Treinamento dos Modelos**
> - Modelos: **Regress√£o Log√≠stica e √Årvore de Decis√£o**.
> - Ferramentas: **PyCaret, MLFlow** para rastreamento de experimentos.
>
> **5Ô∏è‚É£ Avalia√ß√£o dos Modelos**
> - C√°lculo de m√©tricas: **Log-Loss e F1-score**.
> - Compara√ß√£o dos modelos para sele√ß√£o do melhor.
>
> **6Ô∏è‚É£ Deploy/Operacionaliza√ß√£o**
> - O modelo escolhido √© armazenado e carregado para previs√µes em produ√ß√£o.
> - Implementa√ß√£o realizada com **MLflow** para versionamento e rastreamento do modelo, e **Streamlit** para dashboards interativos.
>
> **7Ô∏è‚É£ Monitoramento do Modelo**
> - Monitoramento cont√≠nuo da performance do modelo em produ√ß√£o com registro de m√©tricas como **Log Loss** e **F1 Score** no **MLflow**.
> - An√°lises visuais e interativas com **Streamlit**, permitindo acompanhamento da sa√∫de do modelo, compara√ß√£o entre acertos e erros, e detec√ß√£o de poss√≠veis desvios de comportamento (drift).
>
> **8Ô∏è‚É£ Atualiza√ß√£o do Modelo**
> - Estrat√©gias:
>   - **Reativa**: Atualiza quando a performance do modelo cai.
>   - **Preditiva**: Prev√™ mudan√ßas e ajusta o modelo antes da degrada√ß√£o.
> 
> **Diagrama**
> <br><br>
> ![Diagrama](/Docs/Diagramas/fluxograma_questao2.png)
> <br><br>
> ![Diagrama](/Docs/Diagramas/Diagrama_do_projeto.drawio.png)
>

### **Quest√£o 3)**
#### Como as ferramentas Streamlit, MLFlow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines descritos anteriormente? A resposta deve abranger os seguintes aspectos: <br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a. Rastreamento de experimentos;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b. Fun√ß√µes de treinamento;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c. Monitoramento da sa√∫de do modelo;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d. Atualiza√ß√£o de modelo;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e. Provisionamento (Deployment).
> Resposta:
><br><br>
> A constru√ß√£o do pipeline de Machine Learning segue a estrutura definida no Framework TDSP, permitindo que cada ferramenta desempenhe um papel espec√≠fico dentro do fluxo de trabalho.
> <br>
> A seguir, uma explica√ß√£o de como Streamlit, MLFlow, PyCaret e Scikit-Learn auxiliam em cada uma das fases do projeto:
> <br><br>
> **a. Rastreamento de Experimentos**
> <br>
> üõ†Ô∏è Ferramenta principal: MLFlow
> - O MLFlow permite registrar m√©tricas, par√¢metros e artefatos de cada experimento.
> - Isso facilita a compara√ß√£o de diferentes modelos e vers√µes treinadas.
> - No nosso pipeline, cada modelo ser√° registrado no MLFlow, garantindo rastreabilidade.
>
> üõ†Ô∏è PyCaret tamb√©m auxilia
> <br>
> - O PyCaret j√° possui integra√ß√£o nativa com o MLFlow, facilitando o log autom√°tico dos experimentos.
> - Isso simplifica o rastreamento sem precisar adicionar c√≥digo extra.
> 
> **b. Fun√ß√µes de Treinamento**
> <br>üõ†Ô∏è Ferramentas principais: PyCaret e Scikit-Learn
> - PyCaret automatiza o processo de treinamento, permitindo testar m√∫ltiplos modelos rapidamente.
> - Scikit-Learn fornece as bibliotecas base para treinar modelos, como Regress√£o Log√≠stica e √Årvore de Decis√£o.
> - No nosso pipeline, utilizamos PyCaret para selecionar e avaliar os melhores modelos.
> 
> - O MLFlow pode ser usado para registrar os modelos treinados, salvando artefatos para deploy futuro.
>
> **c. Monitoramento da Sa√∫de do Modelo**
> <br>üõ†Ô∏è Ferramentas principais: MLFlow e Streamlit
> - MLFlow armazena logs das execu√ß√µes dos modelos em produ√ß√£o, possibilitando a an√°lise de degrada√ß√£o do desempenho.
> - Streamlit pode ser usado para criar dashboards interativos e monitorar m√©tricas como Log Loss e F1-score.
> 
> **d. Atualiza√ß√£o do Modelo**
> <br>üõ†Ô∏è Ferramentas principais: MLFlow e PyCaret
> - O modelo pode ser atualizado atrav√©s de estrat√©gias reativas e preditivas.
> - O MLFlow permite versionar diferentes treinamentos, facilitando a troca do modelo sempre que houver degrada√ß√£o.
> - O PyCaret facilita o re-treinamento do modelo de forma simples:
> - Essa abordagem facilita a implanta√ß√£o de novos modelos sem impactar a opera√ß√£o.
>
> **e. Provisionamento (Deployment)**
> <br>üõ†Ô∏è Ferramentas principais: MLFlow e Streamlit
> - O MLFlow Models permite exportar e servir modelos automaticamente como uma API:
> - Streamlit pode ser usado para criar uma interface gr√°fica, permitindo que usu√°rios fa√ßam previs√µes diretamente pelo navegador.
>
> Isso facilita a intera√ß√£o com o modelo sem precisar de habilidades t√©cnicas.
>
> **Conclus√£o Final**
>
> Cada ferramenta desempenha um papel fundamental no pipeline de Machine Learning:
>
| **Ferramenta**    | **Fun√ß√£o Principal** |
|-------------------|-----------------------------------------------|
| **MLFlow**       | Rastreamento de experimentos, versionamento de modelos e monitoramento |
| **PyCaret**      | Automa√ß√£o de treinamento e compara√ß√£o de modelos |
| **Scikit-Learn** | Implementa√ß√£o dos modelos cl√°ssicos de Machine Learning |
| **Streamlit**    | Constru√ß√£o de dashboards para visualiza√ß√£o e deploy interativo |
>
> Com essa abordagem, garantimos um pipeline eficiente, rastre√°vel e totalmente operacional, atendendo √†s exig√™ncias do TDSP e permitindo um fluxo cont√≠nuo de treinamento, avalia√ß√£o, deploy e monitoramento. 

### **Quest√£o 4)**
#### Com base no diagrama realizado na quest√£o 2, aponte os artefatos que ser√£o criados ao longo de um projeto. Para cada artefato, a descri√ß√£o detalhada de sua composi√ß√£o.

> Resposta:

| Artefato | Descri√ß√£o |
|----------|-----------|
| Data/Processed/data_filtered.parquet | Conjunto de dados filtrado com colunas relevantes e sem valores ausentes, utilizado como base para modelagem. |
| Data/Processed/base_train.parquet | Subconjunto de dados estratificado (80%) utilizado para o treinamento dos modelos. |
| Data/Processed/base_test.parquet | Subconjunto de dados estratificado (20%) utilizado para avalia√ß√£o da performance dos modelos. |
| Data/Processed/predictions_prod.parquet | Arquivo contendo as predi√ß√µes geradas pelo modelo final aplicadas √† base de produ√ß√£o. |
| Data/Modeling/modelo_final.pkl | Modelo final treinado e serializado com PyCaret, pronto para ser servido em ambiente produtivo. |
| Data/Logs/simulacoes.csv | Hist√≥rico das simula√ß√µes realizadas no dashboard interativo de simula√ß√£o desenvolvido com Streamlit. |
| Code/DataPrep/preparacao_dados.py | Script respons√°vel pela prepara√ß√£o e limpeza dos dados brutos, incluindo filtragem de colunas e remo√ß√£o de nulos. |
| Code/Model/train_model.py | Notebook contendo o pipeline de treinamento dos modelos, registro no MLflow e avalia√ß√£o de m√©tricas. |
| Code/Operationalization/aplicacao.py | Script para operacionaliza√ß√£o do modelo via API local, permitindo infer√™ncia externa. |
| Code/Operationalization/streamlit_dashboard.py | Dashboard desenvolvido em Streamlit para visualiza√ß√£o de m√©tricas e monitoramento do modelo em produ√ß√£o. |
| Code/Operationalization/streamlit_dashboard_simulacao.py | Dashboard desenvolvido em Streamlit para simula√ß√µes e mapa de Arremesso. |
| Code/Operationalization/streamlit_dashboard_mapa.py | Dashboard desenvolvido em Streamlit da localiza√ß√£o dos arremessos - Kobe Bryant. |
|Docs/Diagramas/fluxograma_questao2.png	| Diagrama representando as etapas do pipeline segundo o TDSP |
|Docs/Diagramas/Diagrama_do_projeto.drawio.png | Arquitetura detalhada do fluxo de dados e execu√ß√£o do projeto |

### **Quest√£o 5)**
#### Implemente o pipeline de processamento de dados com o mlflow, rodada (run) com o nome "PreparacaoDados":<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a. Os dados devem estar localizados em "/data/raw/dataset_kobe_dev.parquet" e "/data/raw/dataset_kobe_prod.parquet"<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.Observe que h√° dados faltantes na base de dados! As linhas que possuem dados faltantes devem ser desconsideradas. Para esse exerc√≠cio ser√£o apenas consideradas as colunas:<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i. lat<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ii. lng<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iii. minutes remaining<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iv. period<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;v. playoffs<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi. shot_distance<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A vari√°vel shot_made_flag ser√° seu alvo, onde 0 indica que Kobe errou e 1 que a cesta foi realizada. O dataset resultante ser√° armazenado na pasta "/data/processed/data_filtered.parquet". Ainda sobre essa sele√ß√£o, qual a dimens√£o resultante do dataset?<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vii. Separe os dados em treino (80%) e teste (20 %) usando uma escolha aleat√≥ria e estratificada. Armazene os datasets resultantes em "/Data/processed/base_{train|test}.parquet . Explique como a escolha de treino e teste afetam o resultado do modelo final. Quais estrat√©gias ajudam a minimizar os efeitos de vi√©s de dados.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; viii. Registre os par√¢metros (% teste) e m√©tricas (tamanho de cada base) no MlFlow

> Resposta:
>
> a.<br>
> Os dados utilizados foram carregados a partir dos arquivos:
> - `/Data/Raw/dataset_kobe_dev.parquet` (base de desenvolvimento)
> - `/Data/Raw/dataset_kobe_prod.parquet` (base de produ√ß√£o, usada posteriormente na aplica√ß√£o)
> 
> b.<br>
> Durante a etapa de prepara√ß√£o, foram selecionadas apenas as seguintes colunas, conforme solicitado:
> 
> - `lat`: latitude 
> - `lon`: longitude 
> - `minutes_remaining`: minutos restantes no per√≠odo da partida.
> - `period`: n√∫mero do per√≠odo (1 a 4 ou prorroga√ß√µes).
> - `playoffs`: indica se a partida √© de playoff (1) ou temporada regular (0).
> - `shot_distance`: dist√¢ncia do arremesso at√© a cesta (em p√©s).
> - `shot_made_flag`: vari√°vel alvo. Valor 1 indica acerto, valor 0 indica erro.
> 
> Linhas com qualquer valor nulo nessas colunas foram removidas, como etapa de limpeza obrigat√≥ria. Ap√≥s essa filtragem, o dataset foi salvo em: `/Data/Processed/data_filtered.parquet`
>
> A dimens√£o resultante do dataset ap√≥s o filtro foi:
> - **20.285 linhas**
> - **7 colunas**
>
> As 7 colunas finais foram: `lat`, `lon`, `minutes_remaining`, `period`, `playoffs`, `shot_distance`, `shot_made_flag`.
>
> Essa vers√£o processada dos dados foi registrada no MLflow na rodada chamada `"PreparacaoDados"`, junto com os par√¢metros e m√©tricas utilizadas.
> 
> Separa√ß√£o entre treino e teste com amostragem estratificada<br>
> Ap√≥s a filtragem, os dados foram divididos em:
> - **80% para treino**
> - **20% para teste**
>
> Utilizamos a t√©cnica de **amostragem estratificada** com base na vari√°vel `shot_made_flag`, o que garante que a propor√ß√£o entre acertos e erros seja mantida em ambos os conjuntos.
>
> Os arquivos gerados foram:
> - `/Data/Processed/base_train.parquet`
> - `/Data/Processed/base_test.parquet`
>
> Essa divis√£o foi essencial para que o modelo fosse avaliado de maneira justa em dados **n√£o vistos**, simulando um ambiente de produ√ß√£o real.
>
> A separa√ß√£o estratificada ajuda a manter a propor√ß√£o de classes entre treino e teste. Para minimizar vi√©s, √© importante garantir que o conjunto de treino seja representativo do dom√≠nio do problema, usar valida√ß√£o cruzada e monitorar m√©tricas de performance em dados fora da amostra.
>
> üìä Registro no MLflow:
> 
> Durante a etapa `"PreparacaoDados"`, registramos os seguintes par√¢metros e m√©tricas no MLflow:
>- **Par√¢metro**
>  <br>`test_size`: 0.2
>
>- **M√©tricas**
>  <br>`Total filtrado (dados limpos)`: 20.285 linhas e 7 colunas
>  <br>`Base de treino`: 16.228 linhas (80%)
>  <br>`Base de teste`: 4.057 linhas (20%)
>  <br>`Train (PyCaret ap√≥s split interno)`: 11.359 linhas
>  <br>`Test (PyCaret ap√≥s split interno)`: 4.869 linhas
> 
> Essas informa√ß√µes s√£o importantes para rastreabilidade do experimento e ajudam na reprodutibilidade do pipeline ao longo do tempo.
> 
### **Quest√£o 6)**
#### Implementar o pipeline de treinamento do modelo com o MlFlow usando o nome "Treinamento"<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a.Com os dados separados para treinamento, treine um modelo com regress√£o log√≠stica do sklearn usando a biblioteca pyCaret.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.Registre a fun√ß√£o custo "log loss" usando a base de teste<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c.Com os dados separados para treinamento, treine um modelo de √°rvore de decis√£o do sklearn usando a biblioteca pyCaret.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d.Registre a fun√ß√£o custo "log loss" e F1_score para o modelo de √°rvore.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e.Selecione um dos dois modelos para finaliza√ß√£o e justifique sua escolha.

> Resposta:
> 
> A partir das bases geradas no pipeline de prepara√ß√£o (`base_train.parquet` e `base_test.parquet`), realizamos o treinamento de dois modelos de classifica√ß√£o usando a biblioteca PyCaret e rastreamento com MLflow, na rodada `"Treinamento"`.
> <br><br>
> **a. Regress√£o Log√≠stica com PyCaret**
> 
> O primeiro modelo treinado foi uma **regress√£o log√≠stica**, utilizando a fun√ß√£o `create_model("lr")` do PyCaret, com os dados de treino.
> 
> O PyCaret foi configurado com:
> - Target: `shot_made_flag`
> - Fold cross-validation: `StratifiedKFold`, com 10 dobras
> - Logging no MLflow: ativado com `log_experiment=True`
> 
> **b. Registro da fun√ß√£o de custo (log loss) ‚Äì Regress√£o Log√≠stica**
> 
> O desempenho do modelo de regress√£o log√≠stica foi avaliado com base na m√©trica **log loss** utilizando os dados de teste.  
> Essa m√©trica foi registrada no MLflow com a tag `"log_loss_lr"`.
> 
> üìä **Resultados da Regress√£o Log√≠stica:**
> - **Log Loss (teste):** `0.6785`
> - **F1 Score (teste):** `0.5129`
> - **F1 Score (cross-val):** `0.5240`
> 
> üì¶ **Desempenho em Produ√ß√£o:**
> - **Log Loss (produ√ß√£o):** `0.6289`
> - **F1 Score (produ√ß√£o):** `0.1645`
> 
> **c. √Årvore de Decis√£o com PyCaret**
> 
> Em seguida, treinamos um modelo de **√°rvore de decis√£o**, com a fun√ß√£o `create_model("dt")` do PyCaret, utilizando os mesmos dados.
> 
> **d. Registro das m√©tricas ‚Äì √Årvore de Decis√£o**
> 
> Para o modelo de √°rvore de decis√£o, foram registradas as seguintes m√©tricas no MLflow:
> - **Log Loss (teste)**: `0.6903`
> - **F1 Score (teste)**: `0.1072`
> - **F1 Score (cross-validation)**: `0.5392`
> 
> As m√©tricas foram registradas com as tags:
> - `"log_loss_dt"`
> - `"f1_dt"`
> 
> **e. Escolha do modelo final**
> 
> O modelo selecionado para uso em produ√ß√£o foi a **Regress√£o Log√≠stica**, pelos seguintes motivos:
> 
> - Apresentou **menor Log Loss em teste** (`0.6785`) e **em produ√ß√£o** (`0.6289`);
> - Teve **comportamento mais est√°vel** entre treino, teste e produ√ß√£o;
> - A √°rvore de decis√£o apresentou sinais de **overfitting**, com desempenho razo√°vel no treino mas queda significativa nos dados reais;
> - A regress√£o log√≠stica √© um modelo **mais robusto e generaliz√°vel**, o que √© desej√°vel para opera√ß√£o cont√≠nua.
> 
> O modelo final foi salvo como `modelo_final.pkl` na pasta `/data/modeling/`, e a rodada de treinamento foi registrada no MLflow com o nome `"Treinamento"`.
>
>
> **üìà Comparativo Final das M√©tricas (Produ√ß√£o)**
>
| Modelo              | Log Loss | F1 Score |
|---------------------|----------|----------|
| Regress√£o Log√≠stica | 0.62888  | 0.1645   |
| √Årvore de Decis√£o   | 0.6903   | 0.1072   |

![Pipeline Status](https://img.shields.io/badge/pipeline-success-brightgreen)


### **Quest√£o 7)**
#### Registre o modelo de classifica√ß√£o e o sirva atrav√©s do MLFlow (ou como uma API local, ou embarcando o modelo na aplica√ß√£o). Desenvolva um pipeline de aplica√ß√£o (aplicacao.py) para carregar a base de produ√ß√£o (/data/raw/dataset_kobe_prod.parquet) e aplicar o modelo. Nomeie a rodada (run) do mlflow como ‚ÄúPipelineAplicacao‚Äù e publique, tanto uma tabela com os resultados obtidos (artefato como .parquet), quanto log as m√©tricas do novo log loss e f1_score do modelo.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a.O modelo √© aderente a essa nova base? O que mudou entre uma base e outra? Justifique.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.Descreva como podemos monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel resposta para o modelo em opera√ß√£o.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c.Descreva as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o.

> Resposta:
>
> **Implementa√ß√£o:**
>
> - O modelo foi servido via `aplicacao.py`, que carrega a base de produ√ß√£o, aplica predi√ß√µes com **threshold=0.35** e registra m√©tricas no MLflow.
>
> ‚ÑπÔ∏è *Nota:* O threshold de 0.35 foi definido ap√≥s an√°lise da curva ROC e otimiza√ß√£o do F1-Score na base de valida√ß√£o. Esse valor equilibra a taxa de acertos (recall) e a precis√£o, garantindo que o modelo n√£o seja excessivamente conservador nem gere muitos falsos positivos.
>
> **a. Ader√™ncia do Modelo:**
> 
> - **Ader√™ncia parcial:** A base de produ√ß√£o apresenta diferen√ßas na distribui√ß√£o de `shot_distance` e `period`, resultando em F1-Score menor (0.1645 vs. 0.5129 em teste).
> 
> **b. Monitoramento:**
> 
> - **Com vari√°vel resposta:** Acompanhamento de Log Loss e F1-Score.
> 
> - **Sem vari√°vel resposta:** An√°lise de distribui√ß√£o de features (PSI, KS Test) e confian√ßa das predi√ß√µes.
> 
> **c. Estrat√©gias de Retreinamento:**
> 
> - **Reativa:** Reentrena o modelo ap√≥s detec√ß√£o de queda no F1-Score.
> 
> - **Preditiva:** Reentrena com base em alertas de drift (ex: mudan√ßa na distribui√ß√£o de `shot_distance`).
> 

### **Quest√£o 8)**
#### Implemente um dashboard de monitoramento da opera√ß√£o usando Streamlit.

> Resposta:
>
> Para viabilizar o monitoramento visual da opera√ß√£o do modelo em produ√ß√£o, foi implementado um **dashboard interativo com Streamlit**, localizado no arquivo:
> 
```
‚îÄ‚îÄ Code/
   ‚îî‚îÄ‚îÄ Operationalization/
       ‚îú‚îÄ‚îÄ streamlit_dashboard_mapa.py
       ‚îú‚îÄ‚îÄ streamlit_dashboard_simulacao.py
       ‚îî‚îÄ‚îÄ streamlit_dashboard.py
```
> **Objetivos do Dashboard**
> 
> - Visualizar a distribui√ß√£o dos arremessos por posi√ß√£o
> - Exibir m√©tricas atualizadas de desempenho do modelo, como **Log Loss** e **F1 Score**
> - Permitir an√°lise comparativa entre acertos e erros de arremessos
> - Oferecer **filtros interativos** por:
>   - Dist√¢ncia do arremesso (`shot_distance`)
>   - Per√≠odo da partida (`period`)
>   - Tipo de jogo (`playoffs`)
> - Exibir visualiza√ß√µes como:
>   - **Mapa de arremessos**
>   - **Heatmap** da quadra
>   - M√©tricas agregadas e contagens
> 
> üõ†Ô∏è Funcionalidades Implementadas
> 
> - Leitura autom√°tica da base processada: `Data/Processed/predictions_prod.parquet`.
> - Cada dashboard atende a um prop√≥sito espec√≠fico:
>   - `streamlit_dashboard_mapa.py`: visualiza√ß√£o dos arremessos na quadra
>   - `streamlit_dashboard_simulacao.py`: simula√ß√£o e teste de predi√ß√µes
>   - `streamlit_dashboard.py`: painel anal√≠tico geral com m√©tricas agregadas
> - Filtros com Streamlit (`slider`, `checkboxes`) para refinar visualiza√ß√µes
> - Gr√°fico de dispers√£o com acertos e erros de arremessos sobre o mapa da quadra
> - **Heatmap de densidade** para identificar regi√µes de maior volume de arremessos
> - C√°lculo e exibi√ß√£o das m√©tricas (Log Loss e F1 Score) com base na produ√ß√£o
> - Layout responsivo com interface amig√°vel e interativa
>
> ### Print Screen das telas do Dashboard e MLflow
> 
> **Streamlit - Dashboard - Mapa de Arremessos - Modelo Kobe Bryant**
>
> ![alt text](/Docs/Imagens/image_dashboard_mapa_arremessos_parte1.png)
>
> **Streamlit - Dashboard - Simula√ß√£o de arremessos - Modelo Kobe Bryant**
>
> ![alt text](/Docs/Imagens/image_dashboard_simulacao_arremessos_parte1.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_simulacao_arremessos_parte2.png)
> 
> ![alt text](/Docs/Imagens/image_dashboard_simulacao_arremessos_parte3.png)
> 
> **Streamlit - Dashboard Anal√≠tico - Modelo Kobe Bryant**
> 
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte1.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte2.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte3.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte4.png)
>
> **MLflow - PreparacaoDados**
> 
> ![alt text](/Docs/Imagens/image_mlflow_PreparacaoDados.png)
> 
> **MLflow - Treinamento**
>
> ![alt text](/Docs/Imagens/image_mlflow_Treinamento_parte1.png)
>
> ![alt text](/Docs/Imagens/image_mlflow_Treinamento_parte2.png)
> 
> **MLflow - PipelineAplicacao**
>
> ![alt text](/Docs/Imagens/image_mlflow_PipelineAplicacao_parte1.png)
>
> ![alt text](/Docs/Imagens/image_mlflow_PipelineAplicacao_parte2.png)
>
> ![alt text](/Docs/Imagens/image_mlflow_PipelineAplicacao_parte3.png)

-------

## Rubricas e Correspond√™ncia com as Quest√µes

**1. Desenvolver um sistema de coleta de dados usando APIs p√∫blicas**
‚úÖ O aluno categorizou corretamente os dados?
<br>Quest√£o: 5

‚úÖ O aluno integrou a leitura dos dados corretamente √† sua solu√ß√£o?
<br>Quest√µes: 5, 6, 7

‚úÖ O aluno aplicou o modelo em produ√ß√£o (servindo como API ou como solu√ß√£o embarcada)?
<br>Quest√£o: 7

‚úÖ O aluno indicou se o modelo √© aderente √† nova base de dados?
<br>Quest√£o: 7-a

**2. Criar uma solu√ß√£o de streaming de dados usando pipelines**

‚úÖ O aluno criou um reposit√≥rio git com a estrutura de projeto baseado no Framework TDSP da Microsoft?
<br>Quest√£o: 1

‚úÖ O aluno criou um diagrama que mostra todas as etapas necess√°rias para a cria√ß√£o de modelos?
<br>Quest√£o: 2

‚úÖ O aluno treinou um modelo de regress√£o usando PyCaret e MLflow?
<br>Quest√£o: 6-a

‚úÖ O aluno calculou o Log Loss para o modelo de regress√£o e registrou no MLflow?
<br>Quest√£o: 6-b

‚úÖ O aluno treinou um modelo de √°rvore de decis√£o usando PyCaret e MLflow?
<br>Quest√£o: 6-c

‚úÖ O aluno calculou o Log Loss e F1 Score para o modelo de √°rvore de decis√£o e registrou no MLflow?
<br>Quest√£o: 6-d

**3. Preparar um modelo previamente treinado para uma solu√ß√£o de streaming de dados**

‚úÖ O aluno indicou o objetivo e descreveu detalhadamente cada artefato criado no projeto?
<br>Quest√£o: 4

‚úÖ O aluno cobriu todos os artefatos do diagrama proposto?
<br>Quest√£o: 4

‚úÖ O aluno usou o MLFlow para registrar a rodada "Prepara√ß√£o de Dados" com as m√©tricas e argumentos relevantes?
<br>Quest√£o: 5

‚úÖ O aluno removeu os dados faltantes da base?
<br>Quest√£o: 5-b

‚úÖ O aluno selecionou as colunas indicadas para criar o modelo?
<br>Quest√£o: 5-b

‚úÖ O aluno indicou quais as dimens√µes para a base preprocessada?
<br>Quest√£o: 5-b

‚úÖ O aluno criou arquivos para cada fase do processamento e os armazenou nas pastas indicadas?
<br>Quest√£o: 5 + estrutura de projeto

‚úÖ O aluno separou em duas bases, uma para treino e outra para teste?
<br>Quest√£o: 5-vii

‚úÖ O aluno criou um pipeline chamado "Treinamento" no MLflow?
<br>Quest√£o: 6

**4. Estabelecer um m√©todo de como atualizar o modelo empregado em produ√ß√£o**

‚úÖ O aluno identificou a diferen√ßa entre a base de desenvolvimento e produ√ß√£o?
<br>Quest√£o: 7-a

‚úÖ O aluno descreveu como monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel alvo?
<br>Quest√£o: 7-b

‚úÖ O aluno implementou um dashboard de monitoramento da opera√ß√£o usando Streamlit?
<br>Quest√£o: 8

‚úÖ O aluno descreveu as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o?
<br>Quest√£o: 7-c
