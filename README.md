# Projeto Final - Engenharia de Machine Learning (25E1_3)

## üéØ Predi√ß√£o de Arremessos de Kobe Bryant com Machine Learning

Este projeto tem como objetivo desenvolver um modelo preditivo utilizando t√©cnicas de Machine Learning para prever o sucesso dos arremessos realizados pelo famoso jogador de basquete Kobe Bryant durante sua carreira na NBA. O projeto explora abordagens de regress√£o log√≠stica e classifica√ß√£o com √°rvore de decis√£o para prever acertos ou erros dos arremessos.

---

## üß± Estrutura do Projeto (TDSP)

```
infnet-25E1_3/
‚îú‚îÄ‚îÄ Code/
‚îÇ   ‚îú‚îÄ‚îÄ DataPrep/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_preparation.py
‚îÇ   ‚îú‚îÄ‚îÄ Model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
‚îÇ   ‚îî‚îÄ‚îÄ Operationalization/
‚îÇ       ‚îú‚îÄ‚îÄ mlruns/
‚îÇ       ‚îú‚îÄ‚îÄ logs.log
‚îÇ       ‚îú‚îÄ‚îÄ aplicacao.py
‚îÇ       ‚îú‚îÄ‚îÄ main_pipeline.py
‚îÇ       ‚îú‚îÄ‚îÄ streamlit_dashboard_mapa.py
‚îÇ       ‚îú‚îÄ‚îÄ streamlit_dashboard_simulacao.py
‚îÇ       ‚îî‚îÄ‚îÄ streamlit_dashboard.py
‚îú‚îÄ‚îÄ Data/
‚îÇ   ‚îú‚îÄ‚îÄ Logs/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ simulacoes.csv
‚îÇ   ‚îú‚îÄ‚îÄ Raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset_kobe_dev.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_kobe_prod.parquet
‚îÇ   ‚îú‚îÄ‚îÄ Processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_filtered.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_train.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_test.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predictions_prod.parquet
‚îú‚îÄ‚îÄ Docs/
‚îÇ   ‚îú‚îÄ‚îÄ Imagens/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ charlotte_key_zone.jpeg
‚îÇ   ‚îú‚îÄ‚îÄ Diagramas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fluxograma_questao2.png
‚îÇ   ‚îú‚îÄ‚îÄ Project/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Log_execucao_pipeline.md
‚îú‚îÄ‚îÄ Modeling/
‚îÇ   ‚îî‚îÄ‚îÄ modelo_final.pkl
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ environment.yml
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Como Executar

### 1. Criar ambiente Conda e instalar depend√™ncias:
```bash
conda create -n infnet-25E1_3_v2 python=3.9.21
conda activate infnet-25E1_3_v2
pip install -r requirements.txt
```
ou YAML 
```bash
conda env create -f environment.yml
```

### 2. Rodar o pipeline completo:
```bash
python Code/Operationalization/main_pipeline.py
```

### 3. Rodar o dashboard:
```bash
streamlit run Code/Operationalization/streamlit_dashboard_mapa.py
streamlit run Code/Operationalization/streamlit_dashboard_simulacao.py
streamlit run Code/Operationalization/streamlit_dashboard.py
```

### 4. Ver o MLflow (opcional):
```bash
mlflow ui
```
Acesse: [http://localhost:5000](http://localhost:5000)

---

## üõ†Ô∏è Tecnologias Utilizadas
- Python 3.9.21
- PyCaret 3.3.2
- Scikit-Learn 1.4.2
- MLflow 1.30.0
- Streamlit 1.43.2
- Pandas 1.5.3
- NumPy 1.26.4
- Matplotlib 3.7.5
- Seaborn 0.13.2

---

## üìà M√©tricas Finais (Produ√ß√£o)

| **M√©trica**           | **Valor**         |
|-----------------------|-------------------|
| Modelo Escolhido      | Regress√£o Log√≠stica |
| Log Loss (Produ√ß√£o)   | 0.62888            |
| F1-Score (Produ√ß√£o)   | 0.1645             |
| F1-Score (Teste)       | 0.5240             |


> üîç O modelo de **Regress√£o Log√≠stica** foi selecionado para produ√ß√£o por apresentar desempenho mais consistente e estabilidade no ambiente de produ√ß√£o.
>
> üìâ Embora o F1 Score em produ√ß√£o esteja abaixo do obtido na base de teste, o modelo demonstrou ser mais confi√°vel do que a √°rvore de decis√£o, cujo desempenho caiu drasticamente fora da amostra.

---

## üìä Dataset
- [Kaggle - Kobe Bryant Shot Selection](https://www.kaggle.com/c/kobe-bryant-shot-selection/data)
- [Dados de desenvolvimento e produ√ß√£o](https://github.com/tciodaro/eng_ml/tree/main/data)

---

## üß† Projeto para a disciplina:
**Engenharia de Machine Learning (25E1_3)**  
**Instituto Infnet ‚Äì 2025**

---

## üìù Observa√ß√µes finais
- Todos os experimentos e m√©tricas s√£o registrados no MLflow
- O pipeline automatizado contempla 3 etapas: prepara√ß√£o ‚Üí treinamento ‚Üí aplica√ß√£o
- Cada etapa registra uma rodada espec√≠fica no MLflow:
  - `PreparacaoDados`
  - `Treinamento`
  - `PipelineAplicacao`

<br>

# **Respostas do projeto**

### **Quest√£o 1)**
#### A solu√ß√£o criada nesse projeto deve ser disponibilizada em reposit√≥rio git e disponibilizada em servidor de reposit√≥rios (Github (recomendado), Bitbucket ou Gitlab). O projeto deve obedecer o Framework TDSP da Microsoft (estrutura de arquivos, arquivo requirements.txt e arquivo README - com as respostas pedidas nesse projeto, al√©m de outras informa√ß√µes pertinentes). Todos os artefatos produzidos dever√£o conter informa√ß√µes referentes a esse projeto (n√£o ser√£o aceitos documentos vazios ou fora de contexto). Escreva o link para seu reposit√≥rio. 

>Resposta:
> <br>
> Link do GitHub: [https://github.com/ianmsouza/kobe_basketball_shot_prediction](https://github.com/ianmsouza/kobe_basketball_shot_prediction)

### **Quest√£o 2)**
#### Iremos desenvolver um preditor de arremessos usando duas abordagens (regress√£o e classifica√ß√£o) para prever se o "Black Mamba" (apelido de Kobe) acertou ou errou a cesta.<br><br>Baixe os dados de desenvolvimento e produ√ß√£o [aqui](https://github.com/tciodaro/eng_ml/tree/main/data) (datasets: dataset_kobe_dev.parquet e dataset_kobe_prod.parquet). Salve-os numa pasta /data/raw na raiz do seu reposit√≥rio.<br><br>Para come√ßar o desenvolvimento, desenhe um diagrama que demonstra todas as etapas necess√°rias para esse projeto, desde a aquisi√ß√£o de dados, passando pela cria√ß√£o dos modelos, indo at√© a opera√ß√£o do modelo.

> Resposta:
> <br><br>
> **1Ô∏è‚É£ Aquisi√ß√£o de Dados**
> - Coleta dos dados brutos fornecidos (`data.csv`, `dataset_kobe_dev.parquet`, etc.).
> - Armazenamento na pasta `/Data/Raw`.
>
> **2Ô∏è‚É£ Pr√©-processamento dos Dados**
> - Remo√ß√£o de valores ausentes.
> - Sele√ß√£o das colunas relevantes: `lat`, `lon`, `minutes_remaining`, etc.
> - Salvamento dos dados tratados em `/Data/Processed`.
>
> **3Ô∏è‚É£ Separa√ß√£o em Treino/Teste**
> - Separa√ß√£o estratificada dos dados (80% treino, 20% teste).
> - Bases armazenadas em `/Data/Processed/base_train.parquet` e `base_test.parquet`.
>
> **4Ô∏è‚É£ Treinamento dos Modelos**
> - Modelos: **Regress√£o Log√≠stica e √Årvore de Decis√£o**.
> - Ferramentas: **PyCaret, MLFlow** para rastreamento de experimentos.
>
> **5Ô∏è‚É£ Avalia√ß√£o dos Modelos**
> - C√°lculo de m√©tricas: **Log-Loss e F1-score**.
> - Compara√ß√£o dos modelos para sele√ß√£o do melhor.
>
> **6Ô∏è‚É£ Deploy/Operacionaliza√ß√£o**
> - O modelo escolhido √© armazenado e carregado para previs√µes em produ√ß√£o.
> - Implementa√ß√£o realizada com **MLflow** para versionamento e rastreamento do modelo, e **Streamlit** para dashboards interativos.
>
> **7Ô∏è‚É£ Monitoramento do Modelo**
> - Monitoramento cont√≠nuo da performance do modelo em produ√ß√£o com registro de m√©tricas como **Log Loss** e **F1 Score** no **MLflow**.
> - An√°lises visuais e interativas com **Streamlit**, permitindo acompanhamento da sa√∫de do modelo, compara√ß√£o entre acertos e erros, e detec√ß√£o de poss√≠veis desvios de comportamento (drift).
>
> **8Ô∏è‚É£ Atualiza√ß√£o do Modelo**
> - Estrat√©gias:
>   - **Reativa**: Atualiza quando a performance do modelo cai.
>   - **Preditiva**: Prev√™ mudan√ßas e ajusta o modelo antes da degrada√ß√£o.
> 
> **Diagrama**
> <br><br>
> ![Diagrama](/Docs/Diagramas/fluxograma_questao2.png)
> <br><br>
> ![Diagrama](/Docs/Diagramas/Diagrama_do_projeto.drawio.png)
>

### **Quest√£o 3)**
#### Como as ferramentas Streamlit, MLFlow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines descritos anteriormente? A resposta deve abranger os seguintes aspectos: <br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a. Rastreamento de experimentos;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b. Fun√ß√µes de treinamento;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c. Monitoramento da sa√∫de do modelo;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d. Atualiza√ß√£o de modelo;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e. Provisionamento (Deployment).
> Resposta:
><br><br>
> A constru√ß√£o do pipeline de Machine Learning segue a estrutura definida no Framework TDSP, permitindo que cada ferramenta desempenhe um papel espec√≠fico dentro do fluxo de trabalho.
> <br>
> A seguir, uma explica√ß√£o de como Streamlit, MLFlow, PyCaret e Scikit-Learn auxiliam em cada uma das fases do projeto:
> <br><br>
> **a. Rastreamento de Experimentos**
> <br>
> üõ†Ô∏è Ferramenta principal: MLFlow
> - O MLFlow permite registrar m√©tricas, par√¢metros e artefatos de cada experimento.
> - Isso facilita a compara√ß√£o de diferentes modelos e vers√µes treinadas.
> - No nosso pipeline, cada modelo ser√° registrado no MLFlow, garantindo rastreabilidade.
>
> üõ†Ô∏è PyCaret tamb√©m auxilia
> <br>
> - O PyCaret j√° possui integra√ß√£o nativa com o MLFlow, facilitando o log autom√°tico dos experimentos.
> - Isso simplifica o rastreamento sem precisar adicionar c√≥digo extra.
> 
> **b. Fun√ß√µes de Treinamento**
> <br>üõ†Ô∏è Ferramentas principais: PyCaret e Scikit-Learn
> - PyCaret automatiza o processo de treinamento, permitindo testar m√∫ltiplos modelos rapidamente.
> - Scikit-Learn fornece as bibliotecas base para treinar modelos, como Regress√£o Log√≠stica e √Årvore de Decis√£o.
> - No nosso pipeline, utilizamos PyCaret para selecionar e avaliar os melhores modelos.
> 
> - O MLFlow pode ser usado para registrar os modelos treinados, salvando artefatos para deploy futuro.
>
> **c. Monitoramento da Sa√∫de do Modelo**
> <br>üõ†Ô∏è Ferramentas principais: MLFlow e Streamlit
> - MLFlow armazena logs das execu√ß√µes dos modelos em produ√ß√£o, possibilitando a an√°lise de degrada√ß√£o do desempenho.
> - Streamlit pode ser usado para criar dashboards interativos e monitorar m√©tricas como Log Loss e F1-score.
> 
> **d. Atualiza√ß√£o do Modelo**
> <br>üõ†Ô∏è Ferramentas principais: MLFlow e PyCaret
> - O modelo pode ser atualizado atrav√©s de estrat√©gias reativas e preditivas.
> - O MLFlow permite versionar diferentes treinamentos, facilitando a troca do modelo sempre que houver degrada√ß√£o.
> - O PyCaret facilita o re-treinamento do modelo de forma simples:
> - Essa abordagem facilita a implanta√ß√£o de novos modelos sem impactar a opera√ß√£o.
>
> **e. Provisionamento (Deployment)**
> <br>üõ†Ô∏è Ferramentas principais: MLFlow e Streamlit
> - O MLFlow Models permite exportar e servir modelos automaticamente como uma API:
> - Streamlit pode ser usado para criar uma interface gr√°fica, permitindo que usu√°rios fa√ßam previs√µes diretamente pelo navegador.
>
> Isso facilita a intera√ß√£o com o modelo sem precisar de habilidades t√©cnicas.
>
> **Conclus√£o Final**
>
> Cada ferramenta desempenha um papel fundamental no pipeline de Machine Learning:
>
| **Ferramenta**    | **Fun√ß√£o Principal** |
|-------------------|-----------------------------------------------|
| **MLFlow**       | Rastreamento de experimentos, versionamento de modelos e monitoramento |
| **PyCaret**      | Automa√ß√£o de treinamento e compara√ß√£o de modelos |
| **Scikit-Learn** | Implementa√ß√£o dos modelos cl√°ssicos de Machine Learning |
| **Streamlit**    | Constru√ß√£o de dashboards para visualiza√ß√£o e deploy interativo |
>
> Com essa abordagem, garantimos um pipeline eficiente, rastre√°vel e totalmente operacional, atendendo √†s exig√™ncias do TDSP e permitindo um fluxo cont√≠nuo de treinamento, avalia√ß√£o, deploy e monitoramento. 

### **Quest√£o 4)**
#### Com base no diagrama realizado na quest√£o 2, aponte os artefatos que ser√£o criados ao longo de um projeto. Para cada artefato, a descri√ß√£o detalhada de sua composi√ß√£o.

> Resposta:

| Artefato | Descri√ß√£o |
|----------|-----------|
| Data/Processed/data_filtered.parquet | Conjunto de dados filtrado com colunas relevantes e sem valores ausentes, utilizado como base para modelagem. |
| Data/Processed/base_train.parquet | Subconjunto de dados estratificado (80%) utilizado para o treinamento dos modelos. |
| Data/Processed/base_test.parquet | Subconjunto de dados estratificado (20%) utilizado para avalia√ß√£o da performance dos modelos. |
| Data/Processed/predictions_prod.parquet | Arquivo contendo as predi√ß√µes geradas pelo modelo final aplicadas √† base de produ√ß√£o. |
| Data/Modeling/modelo_final.pkl | Modelo final treinado e serializado com PyCaret, pronto para ser servido em ambiente produtivo. |
| Code/DataPrep/preparacao_dados.py | Script respons√°vel pela prepara√ß√£o e limpeza dos dados brutos, incluindo filtragem de colunas e remo√ß√£o de nulos. |
| Code/Model/model_training.ipynb | Notebook contendo o pipeline de treinamento dos modelos, registro no MLflow e avalia√ß√£o de m√©tricas. |
| Code/Operationalization/aplicacao.py | Script para operacionaliza√ß√£o do modelo via API local, permitindo infer√™ncia externa. |
| Code/Operationalization/streamlit_dashboard.py | Dashboard desenvolvido em Streamlit para visualiza√ß√£o de m√©tricas e monitoramento do modelo em produ√ß√£o. |
| Code/Operationalization/streamlit_dashboard_simulacao.py | Dashboard desenvolvido em Streamlit para simula√ß√µes e mapa de Arremesso. |
| Code/Operationalization/streamlit_dashboard_mapa.py | Dashboard desenvolvido em Streamlit da localiza√ß√£o dos arremessos - Kobe Bryant. |
| Data/Logs/simulacoes.csv | Hist√≥rico das simula√ß√µes realizadas no dashboard interativo de simula√ß√£o desenvolvido com Streamlit. |

### **Quest√£o 5)**
#### Implemente o pipeline de processamento de dados com o mlflow, rodada (run) com o nome "PreparacaoDados":<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a. Os dados devem estar localizados em "/data/raw/dataset_kobe_dev.parquet" e "/data/raw/dataset_kobe_prod.parquet"<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.Observe que h√° dados faltantes na base de dados! As linhas que possuem dados faltantes devem ser desconsideradas. Para esse exerc√≠cio ser√£o apenas consideradas as colunas:<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i. lat<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ii. lng<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iii. minutes remaining<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iv. period<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;v. playoffs<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi. shot_distance<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A vari√°vel shot_made_flag ser√° seu alvo, onde 0 indica que Kobe errou e 1 que a cesta foi realizada. O dataset resultante ser√° armazenado na pasta "/data/processed/data_filtered.parquet". Ainda sobre essa sele√ß√£o, qual a dimens√£o resultante do dataset?<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vii. Separe os dados em treino (80%) e teste (20 %) usando uma escolha aleat√≥ria e estratificada. Armazene os datasets resultantes em "/Data/processed/base_{train|test}.parquet . Explique como a escolha de treino e teste afetam o resultado do modelo final. Quais estrat√©gias ajudam a minimizar os efeitos de vi√©s de dados.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; viii. Registre os par√¢metros (% teste) e m√©tricas (tamanho de cada base) no MlFlow

> Resposta:
>
> Os dados utilizados foram carregados a partir dos arquivos:
> - `/Data/Raw/dataset_kobe_dev.parquet` (base de desenvolvimento)
> - `/Data/Raw/dataset_kobe_prod.parquet` (base de produ√ß√£o, usada posteriormente na aplica√ß√£o)
> 
> b.<br>
> Durante a etapa de prepara√ß√£o, foram selecionadas apenas as seguintes colunas, conforme solicitado:
> 
> - `lat`: latitude 
> - `lon`: longitude 
> - `minutes_remaining`: minutos restantes no per√≠odo da partida.
> - `period`: n√∫mero do per√≠odo (1 a 4 ou prorroga√ß√µes).
> - `playoffs`: indica se a partida √© de playoff (1) ou temporada regular (0).
> - `shot_distance`: dist√¢ncia do arremesso at√© a cesta (em p√©s).
> - `shot_made_flag`: vari√°vel alvo. Valor 1 indica acerto, valor 0 indica erro.
> 
> Linhas com qualquer valor nulo nessas colunas foram removidas, como etapa de limpeza obrigat√≥ria. Ap√≥s essa filtragem, o dataset foi salvo em: `/data/processed/data_filtered.parquet`
>
> A dimens√£o resultante do dataset ap√≥s o filtro foi:
> - **20.285 linhas**
> - **7 colunas**
>
> Essa vers√£o processada dos dados foi registrada no MLflow na rodada chamada `"PreparacaoDados"`, junto com os par√¢metros e m√©tricas utilizadas.
> 
> Separa√ß√£o entre treino e teste com amostragem estratificada<br>
> Ap√≥s a filtragem, os dados foram divididos em:
> - **80% para treino**
> - **20% para teste**
>
> Utilizamos a t√©cnica de **amostragem estratificada** com base na vari√°vel `shot_made_flag`, o que garante que a propor√ß√£o entre acertos e erros seja mantida em ambos os conjuntos.
>
> Os arquivos gerados foram:
> - `/data/processed/base_train.parquet`
> - `/data/processed/base_test.parquet`
>
> Essa divis√£o foi essencial para que o modelo fosse avaliado de maneira justa em dados **n√£o vistos**, simulando um ambiente de produ√ß√£o real.
>
> A separa√ß√£o estratificada ajuda a manter a propor√ß√£o de classes entre treino e teste. Para minimizar vi√©s, √© importante garantir que o conjunto de treino seja representativo do dom√≠nio do problema, usar valida√ß√£o cruzada e monitorar m√©tricas de performance em dados fora da amostra.
>
> üìä Registro no MLflow:
> 
> Durante a etapa `"PreparacaoDados"`, registramos os seguintes par√¢metros e m√©tricas no MLflow:
>- **Par√¢metro**
>  <br>`test_size`: 0.2
>
>- **M√©tricas**
>  <br>`Total filtrado (dados limpos)`: 20.285 linhas e 7 colunas
>  <br>`Base de treino`: 16.228 linhas (80%)
>  <br>`Base de teste`: 4.057 linhas (20%)
>  <br>`Train (PyCaret ap√≥s split interno)`: 11.359 linhas
>  <br>`Test (PyCaret ap√≥s split interno)`: 4.869 linhas
> 
> Essas informa√ß√µes s√£o importantes para rastreabilidade do experimento e ajudam na reprodutibilidade do pipeline ao longo do tempo.
> 
### **Quest√£o 6)**
#### Implementar o pipeline de treinamento do modelo com o MlFlow usando o nome "Treinamento"<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a.Com os dados separados para treinamento, treine um modelo com regress√£o log√≠stica do sklearn usando a biblioteca pyCaret.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.Registre a fun√ß√£o custo "log loss" usando a base de teste<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c.Com os dados separados para treinamento, treine um modelo de √°rvore de decis√£o do sklearn usando a biblioteca pyCaret.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d.Registre a fun√ß√£o custo "log loss" e F1_score para o modelo de √°rvore.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e.Selecione um dos dois modelos para finaliza√ß√£o e justifique sua escolha.

> Resposta:
> 
> A partir das bases geradas no pipeline de prepara√ß√£o (`base_train.parquet` e `base_test.parquet`), realizamos o treinamento de dois modelos de classifica√ß√£o usando a biblioteca PyCaret e rastreamento com MLflow, na rodada `"Treinamento"`.
> <br><br>
> **a. Regress√£o Log√≠stica com PyCaret**
> 
> O primeiro modelo treinado foi uma **regress√£o log√≠stica**, utilizando a fun√ß√£o `create_model("lr")` do PyCaret, com os dados de treino.
> 
> O PyCaret foi configurado com:
> - Target: `shot_made_flag`
> - Fold cross-validation: `StratifiedKFold`, com 10 dobras
> - Logging no MLflow: ativado com `log_experiment=True`
> 
> **b. Registro da fun√ß√£o de custo (log loss) ‚Äì Regress√£o Log√≠stica**
> 
> O desempenho do modelo de regress√£o log√≠stica foi avaliado com base na m√©trica **log loss** utilizando os dados de teste.  
> Essa m√©trica foi registrada no MLflow com a tag `"log_loss_lr"`.
> 
> üéØ Resultado da regress√£o log√≠stica:
> - **Log Loss (teste)**: `0.6785` (valor real pode ser obtido no MLflow)
> - **F1 Score (teste)**: `0.5129`
> - **F1 Score m√©dio (cross-val)**: `0.5240`
> 
> **c. √Årvore de Decis√£o com PyCaret**
> 
> Em seguida, treinamos um modelo de **√°rvore de decis√£o**, com a fun√ß√£o `create_model("dt")` do PyCaret, utilizando os mesmos dados.
> 
> **d. Registro das m√©tricas ‚Äì √Årvore de Decis√£o**
> 
> Para o modelo de √°rvore de decis√£o, foram registradas as seguintes m√©tricas no MLflow:
> - **Log Loss (teste)**: `0.6903`
> - **F1 Score (teste)**: `0.1072`
> - **F1 Score (cross-validation)**: `0.5392`
> 
> As m√©tricas foram registradas com as tags:
> - `"log_loss_dt"`
> - `"f1_dt"`
> 
> **e. Escolha do modelo final**
> 
> O modelo selecionado para uso em produ√ß√£o foi a **regress√£o log√≠stica**, pelos seguintes motivos:
>
> - Obteve **comportamento mais est√°vel** na base de produ√ß√£o.
> - Apresentou **melhor log loss** no teste (0.6785).
> - Mesmo com F1-Score modesto (0.1645 em produ√ß√£o), superou a √°rvore, que apresentou valores muito baixos (F1 ‚âà 0.1072 e depois ‚âà 0.09).
> - √â um modelo mais robusto e generaliz√°vel, o que √© desej√°vel para opera√ß√£o cont√≠nua.
> 
> O modelo final foi salvo como `modelo_final.pkl` na pasta `/data/modeling/`, e a rodada de treinamento foi registrada no MLflow com o nome `"Treinamento"`.
> 
| Modelo              | Log Loss | F1 Score |
|---------------------|----------|----------|
| Regress√£o Log√≠stica | 0.62888  | 0.1645   |
| √Årvore de Decis√£o   | 0.6903   | 0.1072   |
![Pipeline Status](https://img.shields.io/badge/pipeline-success-brightgreen)


### **Quest√£o 7)**
#### Registre o modelo de classifica√ß√£o e o sirva atrav√©s do MLFlow (ou como uma API local, ou embarcando o modelo na aplica√ß√£o). Desenvolva um pipeline de aplica√ß√£o (aplicacao.py) para carregar a base de produ√ß√£o (/data/raw/dataset_kobe_prod.parquet) e aplicar o modelo. Nomeie a rodada (run) do mlflow como ‚ÄúPipelineAplicacao‚Äù e publique, tanto uma tabela com os resultados obtidos (artefato como .parquet), quanto log as m√©tricas do novo log loss e f1_score do modelo.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a.O modelo √© aderente a essa nova base? O que mudou entre uma base e outra? Justifique.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.Descreva como podemos monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel resposta para o modelo em opera√ß√£o.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c.Descreva as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o.

> Resposta:
>
> Aplica√ß√£o do modelo
> 
> O pipeline de aplica√ß√£o foi implementado no arquivo `aplicacao.py` (tamb√©m acessado via Streamlit como `streamlit_dashboard_simulacao.py`).  
> Ele realiza as seguintes etapas:
> 
> - Carrega o modelo final salvo (**regress√£o log√≠stica**).
> - L√™ a base de produ√ß√£o em `/data/raw/dataset_kobe_prod.parquet`.
> - Aplica o mesmo pr√©-processamento realizado na base de desenvolvimento.
> - Gera as predi√ß√µes.
> - Calcula m√©tricas: **log loss** e **F1 Score** com os dados da produ√ß√£o (caso a vari√°vel `shot_made_flag` esteja presente).
> - Salva os resultados como `/data/processed/predictions_prod.parquet`.
> - Registra a execu√ß√£o no MLflow com o nome da rodada `"PipelineAplicacao"`.
> 
> **a. O modelo √© aderente a essa nova base? O que mudou entre uma base e outra?**
> 
> O modelo demonstrou **ader√™ncia parcial** √† base de produ√ß√£o.  
> Embora a estrutura das colunas seja a mesma, observou-se uma **diferen√ßa no padr√£o de distribui√ß√£o** de algumas vari√°veis, como `shot_distance` e `minutes_remaining`.
> 
> Al√©m disso, a base de produ√ß√£o apresenta um **F1 Score de aproximadamente 0.1645**, bem inferior ao da base de teste da fase de treinamento, indicando **poss√≠vel mudan√ßa de distribui√ß√£o (concept drift)**.
> 
> Essa diferen√ßa sugere que a base de produ√ß√£o pode conter:
> - Dados de uma etapa final da carreira do jogador.
> - Contextos t√°ticos distintos.
> - Ou at√© partidas com caracter√≠sticas diferentes (mais jogos de playoff, por exemplo).
> 
> **b. Como monitorar a sa√∫de do modelo em produ√ß√£o?**
> 
> üìà Quando a vari√°vel resposta est√° dispon√≠vel:
> 
> - Monitorar m√©tricas de performance como:
>   - **Log Loss**
>   - **F1 Score**
>   - **Acur√°cia**
> - Comparar os resultados com os benchmarks da fase de treino/teste.
> - Visualizar a distribui√ß√£o das predi√ß√µes e da vari√°vel real.
> - Usar ferramentas como MLflow ou dashboards em Streamlit.
> 
> ‚ùì Quando a vari√°vel resposta **n√£o est√° dispon√≠vel**:
>
> - Monitorar **m√©tricas indiretas** como:
>   - Confian√ßa nas predi√ß√µes (ex: m√©dia e desvio padr√£o das probabilidades da classe positiva)
>   - Frequ√™ncia de classes previstas (ex: propor√ß√£o entre 0 e 1 nas predi√ß√µes)
> - Verificar **mudan√ßas na distribui√ß√£o das features** (ex: `shot_distance`, `period`) ao longo do tempo.
> - Usar **m√©todos de detec√ß√£o de drift** como:
>   - KS Test, PSI (Population Stability Index)
>   - DDM (Drift Detection Method)
> 
> **c. Estrat√©gias de retreinamento**
> 
> üîÅ Estrat√©gia Reativa
> 
> - O modelo √© reentrenado **ap√≥s queda de performance** detectada.
> - Requer que a vari√°vel `shot_made_flag` esteja dispon√≠vel ap√≥s algum tempo (labels com delay).
> - Exemplo: agendar reentrenamento mensal com dados rotulados acumulados.
> 
> üîÆ Estrat√©gia Preditiva
> 
> - Reentrenamento ocorre **mesmo sem acesso √† vari√°vel resposta**, com base em alertas:
>   - Mudan√ßas em distribui√ß√µes das features.
>   - Aumento da incerteza nas predi√ß√µes.
> - Pode usar mecanismos automatizados de detec√ß√£o de drift.
> - Estrat√©gia ideal para ambientes com **delay na rotulagem**, como produ√ß√£o real.
> 
> Ambas estrat√©gias podem ser combinadas em um ciclo de MLOps, com **monitoramento cont√≠nuo** e **reavalia√ß√£o peri√≥dica do modelo**.
> 
> As m√©tricas e resultados da aplica√ß√£o foram registradas no MLflow e exibidas no dashboard Streamlit, permitindo acompanhamento cont√≠nuo da opera√ß√£o.
> 

### **Quest√£o 8)**
#### Implemente um dashboard de monitoramento da opera√ß√£o usando Streamlit.

> Resposta:
>
> Para viabilizar o monitoramento visual da opera√ß√£o do modelo em produ√ß√£o, foi implementado um **dashboard interativo com Streamlit**, localizado no arquivo:
> 
```
‚îÄ‚îÄ Code/
   ‚îî‚îÄ‚îÄ Operationalization/
       ‚îú‚îÄ‚îÄ streamlit_dashboard_mapa.py
       ‚îú‚îÄ‚îÄ streamlit_dashboard_simulacao.py
       ‚îî‚îÄ‚îÄ streamlit_dashboard.py
```
> **Objetivos do Dashboard**
> 
> - Visualizar a distribui√ß√£o dos arremessos por posi√ß√£o
> - Exibir m√©tricas atualizadas de desempenho do modelo, como **Log Loss** e **F1 Score**
> - Permitir an√°lise comparativa entre acertos e erros de arremessos
> - Oferecer **filtros interativos** por:
>   - Dist√¢ncia do arremesso (`shot_distance`)
>   - Per√≠odo da partida (`period`)
>   - Tipo de jogo (`playoffs`)
> - Exibir visualiza√ß√µes como:
>   - **Mapa de arremessos**
>   - **Heatmap** da quadra
>   - M√©tricas agregadas e contagens
> 
> üõ†Ô∏è Funcionalidades Implementadas
> 
> - Leitura autom√°tica da base processada: `Data/Processed/predictions_prod.parquet`.
> - Cada dashboard atende a um prop√≥sito espec√≠fico:
>   - `streamlit_dashboard_mapa.py`: visualiza√ß√£o dos arremessos na quadra
>   - `streamlit_dashboard_simulacao.py`: simula√ß√£o e teste de predi√ß√µes
>   - `streamlit_dashboard.py`: painel anal√≠tico geral com m√©tricas agregadas
> - Filtros com Streamlit (`slider`, `checkboxes`) para refinar visualiza√ß√µes
> - Gr√°fico de dispers√£o com acertos e erros de arremessos sobre o mapa da quadra
> - **Heatmap de densidade** para identificar regi√µes de maior volume de arremessos
> - C√°lculo e exibi√ß√£o das m√©tricas (Log Loss e F1 Score) com base na produ√ß√£o
> - Layout responsivo com interface amig√°vel e interativa
>
> ### Print Screen das telas do Dashboard e MLflow
> 
> **Streamlit - Dashboard - Mapa de Arremessos - Modelo Kobe Bryant**
>
> ![alt text](/Docs/Imagens/image_dashboard_mapa_arremessos_parte1.png)
>
> **Streamlit - Dashboard - Simula√ß√£o de arremessos - Modelo Kobe Bryant**
>
> ![alt text](/Docs/Imagens/image_dashboard_simulacao_arremessos_parte1.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_simulacao_arremessos_parte2.png)
> 
> ![alt text](/Docs/Imagens/image_dashboard_simulacao_arremessos_parte3.png)
> 
> **Streamlit - Dashboard Anal√≠tico - Modelo Kobe Bryant**
> 
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte1.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte2.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte3.png)
>
> ![alt text](/Docs/Imagens/image_dashboard_analitico_parte4.png)
>
> **MLflow - PreparacaoDados**
> 
> ![alt text](/Docs/Imagens/image_mlflow_PreparacaoDados.png)
> 
> **MLflow - Treinamento**
>
> ![alt text](/Docs/Imagens/image_mlflow_Treinamento_parte1.png)
>
> ![alt text](/Docs/Imagens/image_mlflow_Treinamento_parte2.png)
> 
> **MLflow - PipelineAplicacao**
>
> ![alt text](/Docs/Imagens/image_mlflow_PipelineAplicacao_parte1.png)
>
> ![alt text](/Docs/Imagens/image_mlflow_PipelineAplicacao_parte2.png)
>
> ![alt text](/Docs/Imagens/image_mlflow_PipelineAplicacao_parte3.png)

-------

## Rubricas e Correspond√™ncia com as Quest√µes

**1. Desenvolver um sistema de coleta de dados usando APIs p√∫blicas**
‚úÖ O aluno categorizou corretamente os dados?
<br>Quest√£o: 5

‚úÖ O aluno integrou a leitura dos dados corretamente √† sua solu√ß√£o?
<br>Quest√µes: 5, 6, 7

‚úÖ O aluno aplicou o modelo em produ√ß√£o (servindo como API ou como solu√ß√£o embarcada)?
<br>Quest√£o: 7

‚úÖ O aluno indicou se o modelo √© aderente √† nova base de dados?
<br>Quest√£o: 7-a

**2. Criar uma solu√ß√£o de streaming de dados usando pipelines**

‚úÖ O aluno criou um reposit√≥rio git com a estrutura de projeto baseado no Framework TDSP da Microsoft?
<br>Quest√£o: 1

‚úÖ O aluno criou um diagrama que mostra todas as etapas necess√°rias para a cria√ß√£o de modelos?
<br>Quest√£o: 2

‚úÖ O aluno treinou um modelo de regress√£o usando PyCaret e MLflow?
<br>Quest√£o: 6-a

‚úÖ O aluno calculou o Log Loss para o modelo de regress√£o e registrou no MLflow?
<br>Quest√£o: 6-b

‚úÖ O aluno treinou um modelo de √°rvore de decis√£o usando PyCaret e MLflow?
<br>Quest√£o: 6-c

‚úÖ O aluno calculou o Log Loss e F1 Score para o modelo de √°rvore de decis√£o e registrou no MLflow?
<br>Quest√£o: 6-d

**3. Preparar um modelo previamente treinado para uma solu√ß√£o de streaming de dados**

‚úÖ O aluno indicou o objetivo e descreveu detalhadamente cada artefato criado no projeto?
<br>Quest√£o: 4

‚úÖ O aluno cobriu todos os artefatos do diagrama proposto?
<br>Quest√£o: 4

‚úÖ O aluno usou o MLFlow para registrar a rodada "Prepara√ß√£o de Dados" com as m√©tricas e argumentos relevantes?
<br>Quest√£o: 5

‚úÖ O aluno removeu os dados faltantes da base?
<br>Quest√£o: 5-b

‚úÖ O aluno selecionou as colunas indicadas para criar o modelo?
<br>Quest√£o: 5-b

‚úÖ O aluno indicou quais as dimens√µes para a base preprocessada?
<br>Quest√£o: 5-b

‚úÖ O aluno criou arquivos para cada fase do processamento e os armazenou nas pastas indicadas?
<br>Quest√£o: 5 + estrutura de projeto

‚úÖ O aluno separou em duas bases, uma para treino e outra para teste?
<br>Quest√£o: 5-vii

‚úÖ O aluno criou um pipeline chamado "Treinamento" no MLflow?
<br>Quest√£o: 6

**4. Estabelecer um m√©todo de como atualizar o modelo empregado em produ√ß√£o**

‚úÖ O aluno identificou a diferen√ßa entre a base de desenvolvimento e produ√ß√£o?
<br>Quest√£o: 7-a

‚úÖ O aluno descreveu como monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel alvo?
<br>Quest√£o: 7-b

‚úÖ O aluno implementou um dashboard de monitoramento da opera√ß√£o usando Streamlit?
<br>Quest√£o: 8

‚úÖ O aluno descreveu as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o?
<br>Quest√£o: 7-c